# app_dashboard.py
from __future__ import annotations

import re
from pathlib import Path
from typing import Optional, List
import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
import unidecode

# =========================
# Config
# =========================
st.set_page_config(
    page_title="üìä Dashboard de Producci√≥n Cient√≠fica",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =========================
# Configuraci√≥n para m√≥viles
# =========================
st.markdown(
    """
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
    @media (max-width: 768px) {
        .main .block-container {
            padding: 1rem;
        }
        .stButton > button {
            width: 100%;
            margin: 5px 0;
        }
        .stDataFrame {
            font-size: 12px;
        }
        .css-1d391kg {
            padding: 0.5rem;
        }
        /* Ajustar columnas para m√≥viles */
        [data-testid="column"] {
            width: 100% !important;
            flex: unset !important;
        }
        /* Ajustar tabs para m√≥viles */
        .stTabs [data-baseweb="tab-list"] {
            gap: 8px;
            flex-wrap: wrap;
        }
        .stTabs [data-baseweb="tab"] {
            padding: 8px 12px;
            font-size: 12px;
            height: auto;
            min-height: 32px;
        }
        /* Ajustar m√©tricas para m√≥viles */
        [data-testid="stMetricValue"] {
            font-size: 14px;
        }
        [data-testid="stMetricLabel"] {
            font-size: 12px;
        }
    }
    </style>
    """,
    unsafe_allow_html=True
)

DEFAULT_XLSX = "dataset_unificado_enriquecido_jcr_PLUS.xlsx"
DEFAULT_SHEET_INDEX = 0

# =========================
# Utils
# =========================
def _first_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    for c in candidates:
        if c in df.columns:
            return c
    return None

def detect_department(affiliation: str) -> str:
    if not isinstance(affiliation, str):
        return "Sin asignar"
    aff = affiliation.lower()
    rules = [
        ("neurolog", "Neurolog√≠a y Psiquiatr√≠a"),
        ("psiquiatr", "Neurolog√≠a y Psiquiatr√≠a"),
        ("oncolog", "Oncolog√≠a"),
        ("pediatr", "Pediatr√≠a"),
        ("ginecol", "Ginecolog√≠a y Obstetricia"),
        ("obstetr", "Ginecolog√≠a y Obstetricia"),
        ("medicina interna", "Medicina Interna"),
        ("internal medicine", "Medicina Interna"),
        ("trauma", "Traumatolog√≠a y Ortopedia"),
        ("ortoped", "Traumatolog√≠a y Ortopedia"),
        ("enfermer", "Enfermer√≠a"),
        ("imagen", "Im√°genes"),
        ("radiolog", "Im√°genes"),
        ("urgenc", "Urgencias"),
        ("cirug", "Cirug√≠a"),
        ("anestesi", "Anestesiolog√≠a"),
        ("cardiol", "Cardiolog√≠a"),
    ]
    for kw, dep in rules:
        if kw in aff:
            return dep
    return "Cl√≠nica Alemana"

def detect_clinical_trial(row: pd.Series) -> bool:
    text = ""
    for col in ["Title", "Abstract", "Publication Type", "Keywords"]:
        if col in row and pd.notna(row[col]):
            text += " " + str(row[col])
    text = text.lower()
    ct_regex = r"(ensayo\s*cl[i√≠]nico|clinical\s*trial|randomi[sz]ed|phase\s*[i1v]+|double\s*blind|placebo\-controlled)"
    return bool(re.search(ct_regex, text))

def extract_authors_cas(affiliations: str) -> str:
    """Extrae autores con afiliaci√≥n Cl√≠nica Alemana (CAS, Clinica Alemana)."""
    if not isinstance(affiliations, str):
        return ""
    parts = re.split(r";|\|", affiliations)
    cas_authors = []
    for part in parts:
        if re.search(r"(CAS|CL[I√ç]NICA\s+ALEMANA)", part, flags=re.I):
            name = part.split(",")[0].strip()
            if name:
                cas_authors.append(name)
    return "; ".join(cas_authors)

# =========================
# Utils
# =========================
import unidecode

def _first_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    """Devuelve la primera columna encontrada en df que est√© en la lista de candidatos."""
    for c in candidates:
        if c in df.columns:
            return c
    return None


def detect_department(affiliation: str) -> str:
    """Clasifica departamentos seg√∫n palabras clave en las afiliaciones."""
    if not isinstance(affiliation, str):
        return "Sin asignar"
    aff = affiliation.lower()
    rules = [
        ("neurolog", "Neurolog√≠a y Psiquiatr√≠a"),
        ("psiquiatr", "Neurolog√≠a y Psiquiatr√≠a"),
        ("oncolog", "Oncolog√≠a"),
        ("pediatr", "Pediatr√≠a"),
        ("ginecol", "Ginecolog√≠a y Obstetricia"),
        ("obstetr", "Ginecolog√≠a y Obstetricia"),
        ("medicina interna", "Medicina Interna"),
        ("internal medicine", "Medicina Interna"),
        ("trauma", "Traumatolog√≠a y Ortopedia"),
        ("ortoped", "Traumatolog√≠a y Ortopedia"),
        ("enfermer", "Enfermer√≠a"),
        ("imagen", "Im√°genes"),
        ("radiolog", "Im√°genes"),
        ("urgenc", "Urgencias"),
        ("cirug", "Cirug√≠a"),
        ("anestesi", "Anestesiolog√≠a"),
        ("cardiol", "Cardiolog√≠a"),
    ]
    for kw, dep in rules:
        if kw in aff:
            return dep
    return "Cl√≠nica Alemana"


def detect_clinical_trial(row: pd.Series) -> bool:
    """Detecta si una publicaci√≥n es un ensayo cl√≠nico a partir de t√≠tulo, abstract o keywords."""
    text = ""
    for col in ["Title", "Abstract", "Publication Type", "Keywords"]:
        if col in row and pd.notna(row[col]):
            text += " " + str(row[col])
    text = text.lower()
    ct_regex = r"(ensayo\s*cl[i√≠]nico|clinical\s*trial|randomi[sz]ed|phase\s*[i1v]+|double\s*blind|placebo\-controlled)"
    return bool(re.search(ct_regex, text))


def extract_authors_cas(affiliations: str) -> str:
    """Extrae autores con afiliaci√≥n Cl√≠nica Alemana (CAS, Clinica Alemana)."""
    if not isinstance(affiliations, str):
        return ""
    parts = re.split(r";|\|", affiliations)
    cas_authors = []
    for part in parts:
        if re.search(r"(CAS|CL[I√ç]NICA\s+ALEMANA)", part, flags=re.I):
            name = part.split(",")[0].strip()
            if name:
                cas_authors.append(name)
    return "; ".join(cas_authors)


def normalize_institution(name: str) -> str:
    if not isinstance(name, str):
        return ""

    # Normalizaci√≥n b√°sica
    key = unidecode.unidecode(name.lower().strip())

    # Reemplazar guiones raros (‚Äì ‚Äî ‚àí) por espacio
    key = re.sub(r"[-‚Äì‚Äî‚àí]", " ", key)

    # Quitar caracteres especiales (mantener solo letras, n√∫meros y espacios)
    key = re.sub(r"[^a-z0-9 ]", " ", key)

    # Colapsar espacios m√∫ltiples
    key = re.sub(r"\s+", " ", key).strip()

    normalization_map = {
        # =====================
        # Chile
        # =====================
        "universidad de chile": "Universidad de Chile",
        "university of chile": "Universidad de Chile",
        "uchile": "Universidad de Chile",

        "pontificia universidad catolica de chile": "Pontificia Universidad Cat√≥lica de Chile",
        "pontifical catholic university of chile": "Pontificia Universidad Cat√≥lica de Chile",
        "universidad catolica de chile": "Pontificia Universidad Cat√≥lica de Chile",
        "uc chile": "Pontificia Universidad Cat√≥lica de Chile",

        # =====================
        # Cl√≠nica Alemana - UDD
        # =====================
        "clinica alemana universidad del desarrollo": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "clinica alemana universidad de desarrollo": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "clinica alemana universidad deldesarrollo": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "clinica alemana universidad d desarrollo": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "clinica alemana universidad": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "clinica alemana universidad udd": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "clinica alemana de santiago": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "clinica alemana": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "alemana clinic": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "udd": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "universidad del desarrollo": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "university of development": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "facultad de medicina clinica alemana universidad del desarrollo": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "instituto de ciencias e innovacion en medicina": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "icim": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "centro de genetica y genomica": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",
        "cegen": "Facultad de Medicina Cl√≠nica Alemana - Universidad del Desarrollo",

        # =====================
        # Hospitales y cl√≠nicas
        # =====================
        "hospital clinico universidad de chile": "Hospital Cl√≠nico Universidad de Chile",
        "hospital clinico universidad catolica": "Hospital Cl√≠nico Universidad Cat√≥lica",
        "hospital clinico puc": "Hospital Cl√≠nico Universidad Cat√≥lica",
        "hospital padre hurtado": "Hospital Padre Hurtado",
        "hospital militar de santiago": "Hospital Militar de Santiago",
        "hospital militar": "Hospital Militar de Santiago",
        "clinica las condes": "Cl√≠nica Las Condes",
        "clc": "Cl√≠nica Las Condes",

        # =====================
        # Internacionales comunes
        # =====================
        "harvard medical school": "Harvard University",
        "harvard univ": "Harvard University",
        "university of california": "University of California",
        "uc berkeley": "University of California",
        "ucsf": "University of California",
        "university of toronto": "University of Toronto",
        "university of sydney": "University of Sydney",
    }

    return normalization_map.get(key, name.title())


def normalize_author(name: str) -> str:
    """Normaliza autores: 'Lavados, P.M.' -> 'Lavados, P.' o 'P. Lavados' seg√∫n convenci√≥n."""
    if not isinstance(name, str) or not name.strip():
        return ""

    name = name.replace(".", "").strip()

    # Caso "Apellido, Nombre"
    if "," in name:
        last, first = [x.strip() for x in name.split(",", 1)]
        if re.fullmatch(r"[A-Z ]+", first, flags=re.I):
            first = " ".join(list(first.replace(" ", "")))
        return f"{last}, {first}".title().strip()

    # Caso "Nombre Apellido"
    parts = name.split()
    parts = [p.strip() for p in parts if p.strip()]
    if len(parts) > 1:
        last = parts[-1].title()
        initials = " ".join([p[0].upper() + "." for p in parts[:-1]])
        return f"{last}, {initials}"
    return " ".join(parts).title()

# =========================
# Normalizaci√≥n de columnas
# =========================
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    # Year
    year_col = _first_col(df, ["_Year", "Year", "Publication Year", "PY", "Year_clean"])
    df["Year"] = pd.to_numeric(df[year_col], errors="coerce") if year_col else pd.NA

    # Open Access
    oa_main = _first_col(df, ["OpenAccess_flag", "Open Access", "OA"])
    if oa_main:
        sr = df[oa_main].astype(str).str.lower().str.strip()
        df["OpenAccess_flag"] = sr.isin({"1","true","t","yes","y","si","s√≠"})
    else:
        oa_cols = [c for c in ["OA_Scopus", "OA_WoS", "OA_PubMed"] if c in df.columns]
        if oa_cols:
            tmp = (
                df[oa_cols]
                .apply(lambda s: s.ast(str).str.lower().str.strip().isin({"1","true","t","yes","y","si","s√≠"}))
                .any(axis=1)
            )
            df["OpenAccess_flag"] = tmp.fillna(False)
        else:
            df["OpenAccess_flag"] = False

    # JIF
    jif_col = _first_col(df, ["Journal Impact Factor", "Impact Factor", "JIF", "JIF_2023", "JCR_IF"])
    df["Journal Impact Factor"] = pd.to_numeric(df[jif_col], errors="coerce").fillna(0) if jif_col else 0

    # Quartile
    q_col = _first_col(df, [
        "JIF Quartile", "JCR Quartile", "JCR_Quartile",
        "JCI Quartile", "SJR Quartile", "SJR_Quartile",
        "Quartile_JCR", "quartile_std", "Quartile",
    ])
    if q_col:
        raw = df[q_col].astype(str).str.upper().str.strip()
        mapping = {
            "1": "Q1", "Q-1": "Q1", "QUARTIL 1": "Q1",
            "2": "Q2", "Q-2": "Q2", "QUARTIL 2": "Q2",
            "3": "Q3", "Q-3": "Q3", "QUARTIL 3": "Q3",
            "4": "Q4", "Q-4": "Q4", "QUARTIL 4": "Q4",
        }
        norm = raw.replace(mapping)
        norm = norm.str.extract(r"(Q[1-4])", expand=False).fillna(norm)
        df["Quartile"] = norm.where(norm.isin(["Q1","Q2","Q3","Q4"]), "Sin cuartil")
    else:
        df["Quartile"] = "Sin cuartil"

    # Departamento
    aff_col = _first_col(df, ["Authors with affiliations", "Affiliations", "Author Affiliations"])
    df["Departamento"] = df[aff_col].apply(detect_department) if aff_col else "Sin asignar"

    # Ensayos cl√≠nicos
    df["ClinicalTrial_flag"] = df.apply(detect_clinical_trial, axis=1)

    # Revistas
    jr_col = _first_col(df, ["Journal_norm", "Journal", "Source Title", "Publication Name", "Source title"])
    df["Journal_norm"] = df[jr_col].fillna("").astype(str).replace({"": "‚Äî"}) if jr_col else "‚Äî"

    # Autores (normales)
    a_col = _first_col(df, ["Author Full Names", "Author full names", "Authors"])
    df["Authors_norm"] = df[a_col].fillna("").astype(str) if a_col else ""

    # Autores CAS (desde affiliations)
    if aff_col:
        df["Authors_CAS"] = df[aff_col].apply(extract_authors_cas)
    else:
        df["Authors_CAS"] = ""

    return df

# =========================
# Carga
# =========================
@st.cache_data(show_spinner=False)
def load_data(uploaded=None) -> pd.DataFrame:
    if uploaded is not None:
        base = pd.read_excel(uploaded, sheet_name=DEFAULT_SHEET_INDEX)
    elif Path(DEFAULT_XLSX).exists():
        base = pd.read_excel(DEFAULT_XLSX, sheet_name=DEFAULT_SHEET_INDEX)
    else:
        st.error(f"No se encontr√≥ `{DEFAULT_XLSX}`. Sube un XLSX en la barra lateral.")
        st.stop()
    return normalize_columns(base)

# =========================
# Filtros (optimizados para m√≥viles)
# =========================
def setup_filters(df):
    st.sidebar.header("üîé Filtros")

    # Usar expansores para organizar los filtros
    with st.sidebar.expander("üìÖ Rango de a√±os", expanded=False):
        if pd.api.types.is_numeric_dtype(df["Year"]) and df["Year"].notna().any():
            y_min, y_max = int(df["Year"].min()), int(df["Year"].max())
        else:
            y_min, y_max = 1900, 2100
        year_range = st.slider("A√±os", y_min, y_max, (y_min, y_max), key="year_slider")

    with st.sidebar.expander("üîì Open Access", expanded=False):
        oa_filter = st.radio("Open Access", ["Todos", "Solo OA", "No OA"], key="oa_radio")

    with st.sidebar.expander("üìä Cuartiles", expanded=False):
        quart_vals = [q for q in ["Q1","Q2","Q3","Q4","Sin cuartil"] if q in df["Quartile"].unique().tolist()] or ["Sin cuartil"]
        quart_filter = st.multiselect("Cuartiles", quart_vals, default=quart_vals, key="quart_multiselect")

    with st.sidebar.expander("üè• Departamentos", expanded=False):
        dept_filter = st.multiselect("Departamentos", sorted(df["Departamento"].astype(str).unique()), default=None, key="dept_multiselect")

    with st.sidebar.expander("üîç B√∫squeda", expanded=False):
        search_term = st.text_input("Buscar en t√≠tulos", key="search_input")
    
    return year_range, oa_filter, quart_filter, dept_filter, search_term

# =========================
# MAIN APP
# =========================
def main():
    # Cargar datos
    up = st.sidebar.file_uploader("üìÇ Sube un XLSX", type=["xlsx"])
    df = load_data(up)
    
    # Configurar filtros
    year_range, oa_filter, quart_filter, dept_filter, search_term = setup_filters(df)
    
    # Aplicar filtros
    mask = pd.Series(True, index=df.index)
    mask &= df["Year"].fillna(-1).astype(int).between(year_range[0], year_range[1])
    if oa_filter == "Solo OA":
        mask &= df["OpenAccess_flag"]
    elif oa_filter == "No OA":
        mask &= ~df["OpenAccess_flag"]
    mask &= df["Quartile"].isin(quart_filter)
    if dept_filter:
        mask &= df["Departamento"].isin(dept_filter)
    if search_term.strip():
        mask &= df["Title"].fillna("").str.contains(search_term, case=False, na=False)

    dff = df.loc[mask].copy()

    # =========================
    # KPIs
    # =========================
    st.header("üìä M√©tricas Principales")
    
    # Primera fila de KPIs
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üìö Publicaciones", f"{len(dff)} / {len(df)}")
    with col2:
        st.metric("üîì % Open Access", f"{100 * dff['OpenAccess_flag'].mean():.1f}%")
    with col3:
        st.metric("üìà Suma JIF", f"{dff['Journal Impact Factor'].sum():.1f}")
    with col4:
        st.metric("üß™ Ensayos cl√≠nicos", int(dff["ClinicalTrial_flag"].sum()))

    # Segunda fila de KPIs
    if "Cited by" in dff.columns:
        total_citas = pd.to_numeric(dff["Cited by"], errors="coerce").fillna(0)
    elif "Times Cited" in dff.columns:
        total_citas = pd.to_numeric(dff["Times Cited"], errors="coerce").fillna(0)
    else:
        total_citas = pd.Series([0]*len(dff))

    h_index = int(sum(total_citas.sort_values(ascending=False).reset_index(drop=True) >= 
                      (np.arange(len(total_citas)) + 1)))

    col5, col6, col7, col8 = st.columns(4)
    with col5:
        st.metric("üìñ Total citas", int(total_citas.sum()))
    with col6:
        st.metric("üìñ Promedio citas", f"{total_citas.mean():.1f}")
    with col7:
        st.metric("üèÜ % en Q1", f"{100 * (dff['Quartile']=='Q1').mean():.1f}%")
    with col8:
        st.metric("üìä h-index", h_index)

    # =========================
    # Pesta√±as (versi√≥n m√≥vil-friendly)
    # =========================
    # Para m√≥viles, mostramos un selectbox en lugar de tabs horizontales
    if st.checkbox("üì± Modo m√≥vil", help="Activar para mejor visualizaci√≥n en dispositivos peque√±os"):
        tab_options = [
            "üìÖ Publicaciones", "üìä Cuartiles", "üîì Open Access",
            "üè• Departamentos", "üìë Revistas", "üë• Autores", 
            "‚òÅÔ∏è Wordcloud", "üìñ Citas", "üåç Colaboraci√≥n", "üå± ODS"
        ]
        selected_tab = st.selectbox("Seleccionar secci√≥n:", tab_options)
        tab_index = tab_options.index(selected_tab)
        
        # Crear un contenedor para la pesta√±a seleccionada
        with st.container():
            if tab_index == 0:
                st.subheader("üìÖ Publicaciones por a√±o")
                g = dff.dropna(subset=["Year"]).astype({"Year": int}).groupby("Year").size().reset_index(name="Publicaciones")
                fig = px.bar(g, x="Year", y="Publicaciones", title="Publicaciones por A√±o")
                fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                st.plotly_chart(fig, use_container_width=True)
                
                st.subheader("üìà Suma JIF por a√±o")
                j = dff.dropna(subset=["Year"]).astype({"Year": int}).groupby("Year")["Journal Impact Factor"].sum().reset_index()
                fig = px.line(j, x="Year", y="Journal Impact Factor", markers=True, title="Suma JIF por A√±o")
                fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                st.plotly_chart(fig, use_container_width=True)
            
            elif tab_index == 1:
                st.subheader("üìä Distribuci√≥n por cuartiles")
                cts = dff["Quartile"].value_counts().reset_index()
                cts.columns = ["Quartile", "Publicaciones"]
                fig = px.pie(cts, names="Quartile", values="Publicaciones", hole=0.4)
                fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                st.plotly_chart(fig, use_container_width=True)
            
            elif tab_index == 2:
                st.subheader("üîì Publicaciones Open Access")
                oa = dff["OpenAccess_flag"].map({True: "Open Access", False: "Closed"}).value_counts().reset_index()
                oa.columns = ["Estado", "Publicaciones"]
                fig = px.pie(oa, names="Estado", values="Publicaciones", hole=0.4)
                fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                st.plotly_chart(fig, use_container_width=True)
            
            elif tab_index == 3:
                st.subheader("üè• Publicaciones por Departamento")
                dep = dff["Departamento"].fillna("Sin asignar").value_counts().reset_index()
                dep.columns = ["Departamento", "Publicaciones"]
                fig = px.bar(dep, x="Departamento", y="Publicaciones", title="Top Departamentos")
                fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                st.plotly_chart(fig, use_container_width=True)
            
            elif tab_index == 4:
                st.subheader("üìë Revistas m√°s frecuentes")
                
                def format_journal_name(name: str) -> str:
                    if not isinstance(name, str) or not name.strip():
                        return "‚Äî"

                    # Eliminar espacios extras
                    formatted = re.sub(r"\s+", " ", name.strip())

                    # Normalizar may√∫sculas: capitalizar cada palabra
                    words = formatted.split()
                    formatted = " ".join([w.capitalize() if len(w) > 2 else w.lower() for w in words])

                    # Correcciones para mantener palabras clave intactas
                    corrections = {
                        "De": "de",
                        "La": "la",
                        "El": "el",
                        "Y": "y",
                        "En": "en",
                        "Del": "del",
                        "Los": "los",
                        "Las": "las",
                        "Journal": "Journal",   # Mantener Journal
                        "Revista": "Revista",   # Mantener Revista
                        "Bmj": "BMJ",           # Correcci√≥n siglas
                        "Nejm": "NEJM",
                        "Lancet": "The Lancet"
                    }
                    for wrong, right in corrections.items():
                        formatted = formatted.replace(f" {wrong} ", f" {right} ")

                    # Diccionario de normalizaci√≥n manual (revistas chilenas)
                    normalization_map = {
                        "Medica Chile": "Revista M√©dica de Chile",
                        "Chilena Pediatria": "Revista Chilena de Pediatr√≠a",
                        "Chilena Radiologia": "Revista Chilena de Radiolog√≠a",
                        "Chilena Infectologia": "Revista Chilena de Infectolog√≠a",
                        "Chilena Obstetricia Y Ginecologia": "Revista Chilena de Obstetricia y Ginecolog√≠a",
                        "Andes Pediatrica": "Revista Andes Pedi√°trica",
                        "Chilena Cirugia": "Revista Chilena de Cirug√≠a",
                        "Chilena Anestesia": "Revista Chilena de Anestesia",
                        "Chilena Enfermedades Respiratorias": "Revista Chilena de Enfermedades Respiratorias",
                        "Medica Clinica Las Condes": "Revista M√©dica Cl√≠nica Las Condes",
                    }

                    return normalization_map.get(formatted, formatted)
                
                # Aplicar formato a los nombres de revistas
                dff["Journal_formatted"] = dff["Journal_norm"].apply(format_journal_name)
                
                journals = dff["Journal_formatted"].fillna("‚Äî").value_counts().head(20).reset_index()
                journals.columns = ["Revista", "Publicaciones"]
                
                # Crear gr√°fico con margen izquierdo suficiente
                fig = px.bar(
                    journals.sort_values("Publicaciones"), 
                    x="Publicaciones", 
                    y="Revista", 
                    orientation="h", 
                    title="Top 20 Revistas"
                )
                
                # Ajustar layout
                fig.update_layout(
                    yaxis=dict(categoryorder='total ascending'),
                    margin=dict(l=10, r=10, t=50, b=10),
                    height=500,
                    yaxis_tickfont=dict(size=10),
                    font=dict(size=10)
                )
                
                # Mostrar valores dentro de las barras
                fig.update_traces(
                    text=journals.sort_values("Publicaciones")["Publicaciones"],
                    textposition='inside',
                    insidetextanchor='start'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(journals, use_container_width=True)
            
            elif tab_index == 5:
                st.subheader("üè• Autores de Cl√≠nica Alemana (CAS)")

                # Procesar autores CAS
                cas_authors = (
                    dff["Authors_CAS"].fillna("")
                    .astype(str)
                    .str.split(r";")
                    .explode()
                    .str.strip()
                    .replace("", np.nan)
                    .dropna()
                )

                def format_to_lastname_initials(name: str) -> str:
                    """
                    Convierte 'Lavados Pm' -> 'Lavados, P.'
                    """
                    if not isinstance(name, str) or not name.strip():
                        return ""
                    parts = name.split()
                    if len(parts) == 1:
                        return parts[0].title()
                    last = parts[0].title()
                    initials = "".join([p[0].upper() + "." for p in parts[1:]])
                    return f"{last}, {initials}"

                if not cas_authors.empty:
                    cas_authors_formatted = cas_authors.apply(format_to_lastname_initials)

                    top_cas = cas_authors_formatted.value_counts().head(20).reset_index()
                    top_cas.columns = ["Autor CAS", "Publicaciones"]
                    top_cas_sorted = top_cas.sort_values("Publicaciones", ascending=True)

                    fig = px.bar(
                        top_cas_sorted,
                        x="Publicaciones",
                        y="Autor CAS",
                        orientation="h",
                        title="Top 20 Autores CAS",
                        text="Publicaciones"
                    )

                    fig.update_layout(
                        yaxis=dict(categoryorder='total ascending'),
                        margin=dict(l=10, r=10, t=50, b=10),
                        height=500,
                        yaxis_tickfont=dict(size=10),
                        title_font=dict(size=14),
                        font=dict(size=10)
                    )

                    fig.update_traces(
                        textposition='inside',
                        insidetextanchor='start',
                        textfont=dict(size=10, color='white'),
                        marker_color='#1f77b4'
                    )

                    st.plotly_chart(fig, use_container_width=True)
                    st.dataframe(
                        top_cas.sort_values("Publicaciones", ascending=False).reset_index(drop=True),
                        use_container_width=True
                    )
                else:
                    st.info("No se detectaron autores CAS en las afiliaciones.")
            
            elif tab_index == 6:
                st.subheader("‚òÅÔ∏è Wordcloud de t√≠tulos")
                try:
                    from wordcloud import WordCloud, STOPWORDS
                    import matplotlib.pyplot as plt
                    
                    custom_stopwords = set(STOPWORDS)
                    custom_stopwords.update([
                        "el","la","los","las","un","una","unos","unas","de","del","y","en","por","para","con",
                        "the","a","an","of","for","to","with","on","at","by","from","they","their","this","that","these","those"
                    ])

                    text = " ".join(dff["Title"].dropna().astype(str).tolist())
                    if text.strip():
                        wc = WordCloud(
                            width=800, height=400,
                            background_color="white",
                            stopwords=custom_stopwords
                        ).generate(text)
                        fig, ax = plt.subplots(figsize=(10, 5))
                        ax.imshow(wc, interpolation="bilinear")
                        ax.axis("off")
                        st.pyplot(fig, use_container_width=True, clear_figure=True)
                    else:
                        st.info("No hay t√≠tulos para construir la nube.")
                except ImportError:
                    st.error("Para usar wordcloud, instala: `pip install wordcloud`")
            
            elif tab_index == 7:
                st.subheader("üìñ Citas por a√±o")
                if not total_citas.empty:
                    citas_year = dff.groupby("Year")[total_citas.name].sum().reset_index()
                    fig = px.bar(citas_year, x="Year", y=total_citas.name, title="Citas por A√±o")
                    fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("No hay datos de citas en este dataset.")
            
            elif tab_index == 8:
                st.subheader("üåç Colaboraci√≥n internacional (instituciones en afiliaciones)")
                if "Affiliations" in dff.columns:
                    # Normalizamos afiliaciones
                    affils = dff["Affiliations"].dropna().astype(str)

                    # Dividir por ; o , para separar instituciones
                    institutions = affils.str.split(r";|,").explode().str.strip()

                    # Filtrar instituciones relevantes (evitamos ruido)
                    institutions = institutions[institutions.str.contains(
                        r"(univ|universidad|hospital|clinic|institut|centre|centro)", 
                        case=False, na=False
                    )]

                    # Eliminar "school", "faculty", "department", etc.
                    institutions = institutions[~institutions.str.contains(
                        r"(school|department|faculty|facultad|division|unidad)", 
                        case=False, na=False
                    )]

                    # Normalizar nombres (usa la funci√≥n definida en utils)
                    institutions = institutions.apply(normalize_institution)

                    # Contar las top instituciones
                    top_institutions = institutions.value_counts().head(15).reset_index()
                    top_institutions.columns = ["Instituci√≥n", "Publicaciones"]

                    fig = px.bar(
                        top_institutions.sort_values("Publicaciones"),
                        x="Publicaciones", y="Instituci√≥n", orientation="h",
                        title="Top Instituciones en Afiliaciones"
                    )
                    fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                    st.plotly_chart(fig, use_container_width=True)
                    st.dataframe(top_institutions, use_container_width=True)
                else:
                    st.info("No se encontraron instituciones en las afiliaciones.")
            
            elif tab_index == 9:
                st.subheader("üå± Publicaciones por ODS")
                if "SDG" in dff.columns:
                    sdg = dff["SDG"].dropna().astype(str).str.split(";").explode().str.strip()
                    sdg_counts = sdg.value_counts().reset_index()
                    sdg_counts.columns = ["ODS", "Publicaciones"]
                    fig = px.bar(
                        sdg_counts.sort_values("Publicaciones"),
                        x="Publicaciones", y="ODS", orientation="h",
                        title="Distribuci√≥n por ODS"
                    )
                    fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                    st.plotly_chart(fig, use_container_width=True)
                    st.dataframe(sdg_counts, use_container_width=True)
                else:
                    st.info("No hay informaci√≥n de ODS en este dataset.")
    
    else:
        # Versi√≥n original para desktop
        tabs = st.tabs([
            "üìÖ Publicaciones", 
            "üìä Cuartiles", 
            "üîì Open Access",
            "üè• Departamentos", 
            "üìë Revistas", 
            "üë• Autores", 
            "‚òÅÔ∏è Wordcloud",
            "üìñ Citas",
            "üåç Colaboraci√≥n",
            "üå± ODS" 
        ])
        
        with tabs[0]:
            st.subheader("üìÖ Publicaciones por a√±o")
            g = dff.dropna(subset=["Year"]).astype({"Year": int}).groupby("Year").size().reset_index(name="Publicaciones")
            fig = px.bar(g, x="Year", y="Publicaciones", title="Publicaciones por A√±o")
            fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
            st.plotly_chart(fig, use_container_width=True)

            st.subheader("üìà Suma JIF por a√±o")
            j = dff.dropna(subset=["Year"]).astype({"Year": int}).groupby("Year")["Journal Impact Factor"].sum().reset_index()
            fig = px.line(j, x="Year", y="Journal Impact Factor", markers=True, title="Suma JIF por A√±o")
            fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
            st.plotly_chart(fig, use_container_width=True)
        
        with tabs[1]:
            st.subheader("üìä Distribuci√≥n por cuartiles")
            cts = dff["Quartile"].value_counts().reset_index()
            cts.columns = ["Quartile", "Publicaciones"]
            fig = px.pie(cts, names="Quartile", values="Publicaciones", hole=0.4)
            fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
            st.plotly_chart(fig, use_container_width=True)
        
        with tabs[2]:
            st.subheader("üîì Publicaciones Open Access")
            oa = dff["OpenAccess_flag"].map({True: "Open Access", False: "Closed"}).value_counts().reset_index()
            oa.columns = ["Estado", "Publicaciones"]
            fig = px.pie(oa, names="Estado", values="Publicaciones", hole=0.4)
            fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
            st.plotly_chart(fig, use_container_width=True)
        
        with tabs[3]:
            st.subheader("üè• Publicaciones por Departamento")
            dep = dff["Departamento"].fillna("Sin asignar").value_counts().reset_index()
            dep.columns = ["Departamento", "Publicaciones"]
            fig = px.bar(dep, x="Departamento", y="Publicaciones", title="Top Departamentos")
            fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
            st.plotly_chart(fig, use_container_width=True)
        
        with tabs[4]:
            st.subheader("üìë Revistas m√°s frecuentes")
            
            def format_journal_name(name: str) -> str:
                if not isinstance(name, str) or not name.strip():
                    return "‚Äî"

                # Eliminar espacios extras
                formatted = re.sub(r"\s+", " ", name.strip())

                # Normalizar may√∫sculas: capitalizar cada palabra
                words = formatted.split()
                formatted = " ".join([w.capitalize() if len(w) > 2 else w.lower() for w in words])

                # Correcciones para mantener palabras clave intactas
                corrections = {
                    "De": "de",
                    "La": "la",
                    "El": "el",
                    "Y": "y",
                    "En": "en",
                    "Del": "del",
                    "Los": "los",
                    "Las": "las",
                    "Journal": "Journal",   # Mantener Journal
                    "Revista": "Revista",   # Mantener Revista
                    "Bmj": "BMJ",           # Correcci√≥n siglas
                    "Nejm": "NEJM",
                    "Lancet": "The Lancet"
                }
                for wrong, right in corrections.items():
                    formatted = formatted.replace(f" {wrong} ", f" {right} ")

                # Diccionario de normalizaci√≥n manual (revistas chilenas)
                normalization_map = {
                    "Medica Chile": "Revista M√©dica de Chile",
                    "Chilena Pediatria": "Revista Chilena de Pediatr√≠a",
                    "Chilena Radiologia": "Revista Chilena de Radiolog√≠a",
                    "Chilena Infectologia": "Revista Chilena de Infectolog√≠a",
                    "Chilena Obstetricia Y Ginecologia": "Revista Chilena de Obstetricia y Ginecolog√≠a",
                    "Andes Pediatrica": "Revista Andes Pedi√°trica",
                    "Chilena Cirugia": "Revista Chilena de Cirug√≠a",
                    "Chilena Anestesia": "Revista Chilena de Anestesia",
                    "Chilena Enfermedades Respiratorias": "Revista Chilena de Enfermedades Respiratorias",
                    "Medica Clinica Las Condes": "Revista M√©dica Cl√≠nica Las Condes",
                }

                return normalization_map.get(formatted, formatted)
            
            # Aplicar formato a los nombres de revistas
            dff["Journal_formatted"] = dff["Journal_norm"].apply(format_journal_name)
            
            journals = dff["Journal_formatted"].fillna("‚Äî").value_counts().head(20).reset_index()
            journals.columns = ["Revista", "Publicaciones"]
            
            # Crear gr√°fico con margen izquierdo suficiente
            fig = px.bar(
                journals.sort_values("Publicaciones"), 
                x="Publicaciones", 
                y="Revista", 
                orientation="h", 
                title="Top 20 Revistas"
            )
            
            # Ajustar layout
            fig.update_layout(
                yaxis=dict(categoryorder='total ascending'),
                margin=dict(l=300, r=10, t=50, b=10),
                height=600,
                yaxis_tickfont=dict(size=12),
                font=dict(size=10)
            )
            
            # Mostrar valores dentro de las barras
            fig.update_traces(
                text=journals.sort_values("Publicaciones")["Publicaciones"],
                textposition='inside',
                insidetextanchor='start'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(journals, use_container_width=True)
        
        with tabs[5]:
            st.subheader("üè• Autores de Cl√≠nica Alemana (CAS)")

            # Procesar autores CAS
            cas_authors = (
                dff["Authors_CAS"].fillna("")
                .astype(str)
                .str.split(r";")
                .explode()
                .str.strip()
                .replace("", np.nan)
                .dropna()
            )

            def format_to_lastname_initials(name: str) -> str:
                """
                Convierte 'Lavados Pm' -> 'Lavados, P.'
                """
                if not isinstance(name, str) or not name.strip():
                    return ""
                parts = name.split()
                if len(parts) == 1:
                    return parts[0].title()
                last = parts[0].title()
                initials = "".join([p[0].upper() + "." for p in parts[1:]])
                return f"{last}, {initials}"

            if not cas_authors.empty:
                cas_authors_formatted = cas_authors.apply(format_to_lastname_initials)

                top_cas = cas_authors_formatted.value_counts().head(20).reset_index()
                top_cas.columns = ["Autor CAS", "Publicaciones"]
                top_cas_sorted = top_cas.sort_values("Publicaciones", ascending=True)

                fig = px.bar(
                    top_cas_sorted,
                    x="Publicaciones",
                    y="Autor CAS",
                    orientation="h",
                    title="Top 20 Autores CAS",
                    text="Publicaciones"
                )

                fig.update_layout(
                    yaxis=dict(categoryorder='total ascending'),
                    margin=dict(l=300, r=10, t=50, b=10),
                    height=600,
                    yaxis_tickfont=dict(size=12),
                    title_font=dict(size=16),
                    font=dict(size=10)
                )

                fig.update_traces(
                    textposition='inside',
                    insidetextanchor='start',
                    textfont=dict(size=11, color='white'),
                    marker_color='#1f77b4'
                )

                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(
                    top_cas.sort_values("Publicaciones", ascending=False).reset_index(drop=True),
                    use_container_width=True
                )
            else:
                st.info("No se detectaron autores CAS en las afiliaciones.")
        
        with tabs[6]:
            st.subheader("‚òÅÔ∏è Wordcloud de t√≠tulos")
            try:
                from wordcloud import WordCloud, STOPWORDS
                import matplotlib.pyplot as plt
                
                custom_stopwords = set(STOPWORDS)
                custom_stopwords.update([
                    "el","la","los","las","un","una","unos","unas","de","del","y","en","por","para","con",
                    "the","a","an","of","for","to","with","on","at","by","from","they","their","this","that","these","those"
                ])

                text = " ".join(dff["Title"].dropna().astype(str).tolist())
                if text.strip():
                    wc = WordCloud(
                        width=1200, height=500,
                        background_color="white",
                        stopwords=custom_stopwords
                    ).generate(text)
                    fig, ax = plt.subplots(figsize=(10, 4))
                    ax.imshow(wc, interpolation="bilinear")
                    ax.axis("off")
                    st.pyplot(fig, use_container_width=True, clear_figure=True)
                else:
                    st.info("No hay t√≠tulos para construir la nube.")
            except ImportError:
                st.error("Para usar wordcloud, instala: `pip install wordcloud`")
        
        with tabs[7]:
            st.subheader("üìñ Citas por a√±o")
            if not total_citas.empty:
                citas_year = dff.groupby("Year")[total_citas.name].sum().reset_index()
                fig = px.bar(citas_year, x="Year", y=total_citas.name, title="Citas por A√±o")
                fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("No hay datos de citas en este dataset.")
        
        with tabs[8]:
            st.subheader("üåç Colaboraci√≥n internacional (instituciones en afiliaciones)")
            if "Affiliations" in dff.columns:
                # Normalizamos afiliaciones
                affils = dff["Affiliations"].dropna().astype(str)

                # Dividir por ; o , para separar instituciones
                institutions = affils.str.split(r";|,").explode().str.strip()

                # Filtrar instituciones relevantes (evitamos ruido)
                institutions = institutions[institutions.str.contains(
                    r"(univ|universidad|hospital|clinic|institut|centre|centro)", 
                    case=False, na=False
                )]

                # Eliminar "school", "faculty", "department", etc.
                institutions = institutions[~institutions.str.contains(
                    r"(school|department|faculty|facultad|division|unidad)", 
                    case=False, na=False
                )]

                # Normalizar nombres (usa la funci√≥n definida en utils)
                institutions = institutions.apply(normalize_institution)

                # Contar las top instituciones
                top_institutions = institutions.value_counts().head(15).reset_index()
                top_institutions.columns = ["Instituci√≥n", "Publicaciones"]

                fig = px.bar(
                    top_institutions.sort_values("Publicaciones"),
                    x="Publicaciones", y="Instituci√≥n", orientation="h",
                    title="Top Instituciones en Afiliaciones"
                )
                fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(top_institutions, use_container_width=True)
            else:
                st.info("No se encontraron instituciones en las afiliaciones.")
        
        with tabs[9]:
            st.subheader("üå± Publicaciones por ODS")
            if "SDG" in dff.columns:
                sdg = dff["SDG"].dropna().astype(str).str.split(";").explode().str.strip()
                sdg_counts = sdg.value_counts().reset_index()
                sdg_counts.columns = ["ODS", "Publicaciones"]
                fig = px.bar(
                    sdg_counts.sort_values("Publicaciones"),
                    x="Publicaciones", y="ODS", orientation="h",
                    title="Distribuci√≥n por ODS"
                )
                fig.update_layout(autosize=True, margin=dict(l=10, r=10, t=50, b=10), font=dict(size=10))
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(sdg_counts, use_container_width=True)
            else:
                st.info("No hay informaci√≥n de ODS en este dataset.")

    # =========================
    # M√≥dulo de carga y merge
    # =========================
    def build_match_key(df: pd.DataFrame) -> pd.Series:
        doi = df.get("DOI", pd.Series([""]*len(df), index=df.index)).fillna("").astype(str)
        pmid = df.get("PMID", pd.Series([""]*len(df), index=df.index)).fillna("").astype(str)
        eid = df.get("EID", pd.Series([""]*len(df), index=df.index)).fillna("").astype(str)
        y = df.get("Year", pd.Series(["-1"]*len(df), index=df.index)).astype(str)
        t = df.get("Title", pd.Series([""]*len(df), index=df.index)).astype(str).str.lower().str.strip()
        ty = "TY:" + y + "|" + t

        key = doi.where(doi != "", "PMID:" + pmid)
        key = key.where(~key.str.startswith("PMID:"), "EID:" + eid)
        key = key.where(~key.str.startswith("EID:"), ty)
        return key

    def merge_preview(old_df: pd.DataFrame, new_df: pd.DataFrame):
        old = old_df.copy(); new = new_df.copy()
        old["_mk"] = build_match_key(old); new["_mk"] = build_match_key(new)
        old_set = set(k for k in old["_mk"] if isinstance(k,str) and k)
        new["_is_new"] = ~new["_mk"].isin(old_set)
        return new

    def merge_apply(old_df: pd.DataFrame, new_df: pd.DataFrame) -> pd.DataFrame:
        a = old_df.copy(); b = new_df.copy()
        a["_mk"] = build_match_key(a); b["_mk"] = build_match_key(b)
        z = pd.concat([a, b], ignore_index=True, sort=False)
        z["_dedup"] = z["_mk"].fillna("") + "|" + z["Title"].fillna("")
        z = z.drop_duplicates(subset="_dedup", keep="first").drop(columns=["_dedup"], errors="ignore")
        return z

    with st.sidebar:
        st.markdown("---")
        st.header("üîÑ Actualizar dataset")
        new_files = st.file_uploader("Nuevos CSV/XLSX", type=["csv","xlsx"], accept_multiple_files=True)
        btn_prev  = st.button("üëÄ Previsualizar uni√≥n")
        btn_apply = st.button("‚úÖ Aplicar actualizaci√≥n", type="primary")

    if new_files:
        tables = []
        for f in new_files:
            try:
                t = pd.read_csv(f, dtype=str) if f.name.lower().endswith(".csv") else pd.read_excel(f, dtype=str)
                tables.append(normalize_columns(t))
            except Exception:
                pass
        new_df = pd.concat(tables, ignore_index=True, sort=False) if tables else pd.DataFrame()
    else:
        new_df = pd.DataFrame()

    if not new_df.empty and btn_prev:
        prev = merge_preview(df, new_df)
        n_new = int(prev["_is_new"].sum())
        n_dup = int(len(prev) - n_new)
        st.sidebar.success(f"Vista previa: {n_new} nuevos ¬∑ {n_dup} duplicados.")

    if not new_df.empty and btn_apply:
        df = merge_apply(df, new_df)
        st.sidebar.success(f"Uni√≥n aplicada. Registros ahora: {len(df):,}")

if __name__ == "__main__":
    main()